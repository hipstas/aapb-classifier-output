{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import attk\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import librosa\n",
    "import timeit\n",
    "import random\n",
    "import subprocess\n",
    "import unicodecsv\n",
    "import urllib2\n",
    "from sklearn.externals import joblib\n",
    "from numpy import ma\n",
    "from aubio import source, pitch\n",
    "from moviepy.audio.io import AudioFileClip\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "classifier_dir = '/sharedfolder/Obama_Batch_4K/sida_classifier/'\n",
    "\n",
    "os.chdir(classifier_dir)\n",
    "\n",
    "speaker_1_label = 'Barack Obama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load saved features\n",
    "\n",
    "def load_features(dir_path):\n",
    "    features = []\n",
    "    for filename in os.listdir(dir_path):\n",
    "        with open(os.path.join(dir_path, filename)) as fi:\n",
    "            csv_reader = csv.reader(fi)\n",
    "            for row in csv_reader:\n",
    "                features.append([float(item) for item in row])\n",
    "    return features\n",
    "\n",
    "speaker_1_features = load_features('/sharedfolder/Obama_Batch_4K/sida_classifier/Obama_400_speeches_cleaned/_vowel_mfccs_and_deltas')\n",
    "print(len(speaker_1_features))\n",
    "\n",
    "speaker_1_features += load_features('/sharedfolder/Obama_Batch_4K/sida_classifier/Obama_weekly_addresses_cleaned/_vowel_mfccs_and_deltas')\n",
    "print(len(speaker_1_features))\n",
    "\n",
    "aapb_ubm_male_features = load_features('/sharedfolder/Obama_Batch_4K/sida_classifier/AAPB_male_vowel_mfccs_and_deltas_100-5K_Hz')\n",
    "print(len(aapb_ubm_male_features))\n",
    "\n",
    "aapb_ubm_female_features = load_features('/sharedfolder/Obama_Batch_4K/sida_classifier/AAPB_female_vowel_mfccs_and_deltas_100-5K_Hz')\n",
    "print(len(aapb_ubm_female_features))\n",
    "\n",
    "the_world_ubm_male_features = load_features('/sharedfolder/Obama_Batch_4K/sida_classifier/The_World_Male_vowel_mfccs_and_deltas')\n",
    "print(len(the_world_ubm_male_features))\n",
    "\n",
    "the_world_ubm_female_features = load_features('/sharedfolder/Obama_Batch_4K/sida_classifier/The_World_Female_vowel_mfccs_and_deltas')\n",
    "print(len(the_world_ubm_female_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def load_features(dir_path):\n",
    "#    features = []\n",
    "#    for filename in [item for item in os.listdir(dir_path) if 'Weekly' in item]:\n",
    "#        with open(os.path.join(dir_path, filename)) as fi:\n",
    "#            csv_reader = csv.reader(fi)\n",
    "#            for row in csv_reader:\n",
    "#                features.append([float(item) for item in row])\n",
    "#    return features\n",
    "\n",
    "#speaker_1_features = load_features('/sharedfolder/sida_classifier/_classes_Obama_training_clips_all/Barack_Obama/_vowel_mfccs_and_deltas')\n",
    "#print(len(speaker_1_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing MFCCs and deltas for a single frame\n",
    "\n",
    "print(random.choice(speaker_1_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining feature sets\n",
    "\n",
    "speaker_1_features = speaker_1_features\n",
    "ubm_features = aapb_ubm_male_features + aapb_ubm_female_features + the_world_ubm_male_features + the_world_ubm_female_features\n",
    "\n",
    "print(len(speaker_1_features))\n",
    "print(len(ubm_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and multi-layer perceptron model with 9/10 of training data and evaluating performance on remaining 1/10\n",
    "\n",
    "os.chdir(classifier_dir)\n",
    "\n",
    "#random.shuffle(speaker_1_features)\n",
    "#random.shuffle(ubm_features)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = speaker_1_features[:-len(speaker_1_features)/10] + ubm_features[:-len(ubm_features)/10]\n",
    "y = [1]*len(speaker_1_features[:-len(speaker_1_features)/10]) + [0]*len(ubm_features[:-len(ubm_features)/10])\n",
    "\n",
    "X_test = speaker_1_features[-len(speaker_1_features)/10:] + ubm_features[-len(ubm_features)/10:]\n",
    "y_test = [1]*len(speaker_1_features[-len(speaker_1_features)/10:]) + [0]*len(ubm_features[-len(ubm_features)/10:])\n",
    "\n",
    "X_train = np.array(X)\n",
    "y_train = np.array(y)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = MLPClassifier(random_state = 10).fit(X_train_scaled, y_train)\n",
    "\n",
    "#classifier = MLPClassifier(max_iter = 2000, random_state = 10, \\\n",
    "#                          hidden_layer_sizes = (100, 100), solver = 'adam', \\\n",
    "#                          activation = 'relu').fit(X_train_scaled, y_train)\n",
    "\n",
    "print(classifier.score(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and saving an MLP model with all training data\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = speaker_1_features + ubm_features\n",
    "y = [1]*len(speaker_1_features) + [0]*len(ubm_features)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "classifier = MLPClassifier().fit(X_scaled, y)\n",
    "\n",
    "trained_model_filename = speaker_1_label.replace(' ', '_') + '_vowels_mlpc_4096_scaled_20170928.pkl'\n",
    "scaler_filename = speaker_1_label.replace(' ', '_') + '_vowels_mlpc_4096_scaled_20170928.scaler'\n",
    "\n",
    "print(trained_model_filename)\n",
    "\n",
    "## Saving trained model\n",
    "\n",
    "joblib.dump(classifier, trained_model_filename)\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "\n",
    "classifier = joblib.load(trained_model_filename)\n",
    "scaler = joblib.load(scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#### Start here to load pre-trained model ####\n",
    "##############################################\n",
    "\n",
    "#os.chdir(classifier_dir)\n",
    "\n",
    "#trained_model_filename = speaker_1_label.replace(' ', '_') + '_vowels_mlpc_4096_scaled_20170928.pkl'\n",
    "#scaler_filename = speaker_1_label.replace(' ', '_') + '_vowels_mlpc_4096_scaled_20170928.scaler'\n",
    "\n",
    "#os.chdir('/sharedfolder/sida_classifier/')\n",
    "#classifier = joblib.load(trained_model_filename)\n",
    "#scaler = joblib.load(scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Download unseen audio and split into 3-second WAV clips for testing\n",
    "\n",
    "os.chdir(classifier_dir)\n",
    "\n",
    "try: os.mkdir('test_clips/')\n",
    "except: pass\n",
    "\n",
    "os.chdir(os.path.join(classifier_dir, 'test_clips/'))\n",
    "\n",
    "mp3_url = \"http://traffic.libsyn.com/wtfpod/WTF_-_EPISODE_613_PRESIDENT_BARACK_OBAMA.mp3\"\n",
    "\n",
    "mp3_filename = os.path.basename(mp3_url)\n",
    "\n",
    "wav_filename = mp3_filename[:-4]+'.wav'\n",
    "\n",
    "subprocess.call(['wget', '-N', mp3_url])\n",
    "\n",
    "subprocess.call(['ffmpeg', '-i', mp3_filename, wav_filename])\n",
    "\n",
    "subprocess.call(['ffmpeg', '-i', wav_filename, '-f', 'segment', '-segment_time', '3',  wav_filename[:-4] + '_3_sec_%04d.wav'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Classifying short clips\n",
    "#### Repeat this cell several times to help choose a classifier threshold value.\n",
    "\n",
    "os.chdir(os.path.join(classifier_dir, 'test_clips/'))\n",
    "\n",
    "wav_pathname = os.path.abspath(random.choice([item for item in os.listdir('./') if '3_sec' in item]))\n",
    "\n",
    "test_features = attk.get_mfccs_and_deltas(wav_pathname)\n",
    "\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "print(wav_pathname)\n",
    "\n",
    "results = classifier.predict(test_features)  ## Predicting new observation\n",
    "\n",
    "print(results)\n",
    "\n",
    "vowel_results=[]\n",
    "\n",
    "vowel_bools = attk.get_vowel_segments(wav_pathname)\n",
    "\n",
    "for i in range(len(results)):\n",
    "    try:\n",
    "        if vowel_bools[i]==True:\n",
    "            vowel_results.append(results[i])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "display(Audio(wav_pathname))\n",
    "\n",
    "print(\"All samples: \"+str(np.mean(results)))\n",
    "print(\"Vowels only: \"+str(np.mean(vowel_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function that classifies vowel segments only and returns \n",
    "## average output for the full clip\n",
    "\n",
    "def classify_clip(clip_pathname):\n",
    "    mfccs = attk.get_mfccs_and_deltas(clip_pathname)\n",
    "    mfccs = scaler.transform(mfccs)\n",
    "    results = classifier.predict(mfccs)  ## Predicting new observation\n",
    "    vowel_results=[]\n",
    "    vowel_bools = attk.get_vowel_segments(clip_pathname)\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        if vowel_bools[i] == True:\n",
    "            vowel_results.append(results[i])\n",
    "\n",
    "    return np.mean(vowel_results) ## Vowels only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Classifying a long audio file\n",
    "\n",
    "resolution_secs = 3.0\n",
    "\n",
    "os.chdir('/sharedfolder/')\n",
    "\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "media_path = \"/sharedfolder/sida_classifier/test_clips/WIWpodcast38.wav\"\n",
    "media_path = \"/sharedfolder/sida_classifier/test_clips/Barack_obama_documentary.2016_HD-ASM0GXVZmv4.wav\"\n",
    "media_path = \"/sharedfolder/sida_classifier/Obama_test_audio/20090219_tmm_obamablog.mp3\"\n",
    "media_path = \"/sharedfolder/sida_classifier/test_clips/Documentaries-20150724-ThePresidentObamaInterview.wav\"\n",
    "media_path = os.path.join(classifier_dir, \"test_clips/WTF_-_EPISODE_613_PRESIDENT_BARACK_OBAMA.wav\")\n",
    "\n",
    "snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "classifications = []\n",
    "\n",
    "for i in range(int(attk.duration(media_path)/resolution_secs)):\n",
    "    try:\n",
    "        snd.subclip(i * resolution_secs , (i * resolution_secs) + resolution_secs).write_audiofile('/tmp/temp_clip.wav')\n",
    "        classifications.append(classify_clip('/tmp/temp_clip.wav'))\n",
    "    except:\n",
    "        classifications.append(0.0)\n",
    "        print(\"Error: \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Time elapsed: \"+str(timeit.default_timer() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Writing classification output to CSV\n",
    "\n",
    "classifier_threshold = 0.0      # Classifier values below this threshold will be discarded\n",
    "\n",
    "os.chdir(classifier_dir)\n",
    "\n",
    "csv_path = media_path[:-4]+'_mlpc4096_scaled_labels_'+str(resolution_secs)+'s.csv'\n",
    "\n",
    "counter=0\n",
    "\n",
    "with open(csv_path,'w') as fo:\n",
    "    duration = resolution_secs\n",
    "    for value in classifications:\n",
    "        if value >= classifier_threshold:\n",
    "            start = counter * resolution_secs\n",
    "            fo.write(str(start) + ',' + str(duration) +','+ str(value) + ',' + speaker_1_label + '\\n')\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Writing filtered classification output to CSV\n",
    "\n",
    "classifier_threshold = 0.30      # Classifier values below this threshold will be discarded\n",
    "\n",
    "os.chdir(classifier_dir)\n",
    "\n",
    "csv_path = media_path[:-4]+'_mlpc4096_scaled_labels_filtered_'+str(resolution_secs)+'s.csv'\n",
    "\n",
    "counter = 0\n",
    "\n",
    "with open(csv_path,'w') as fo:\n",
    "    duration = resolution_secs\n",
    "    for value in attk.smooth(classifications):\n",
    "        if value >= classifier_threshold:\n",
    "            start = counter * resolution_secs\n",
    "            fo.write(str(start) + ',' + str(duration) +','+ str(value) + ',' + speaker_1_label + '\\n')\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Classifying a long audio file\n",
    "\n",
    "resolution_secs = 3.0\n",
    "\n",
    "os.chdir('/sharedfolder/AAPB_Subset_4000/')\n",
    "\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "media_paths = [os.path.abspath(item) for item in os.listdir('./') if item[-4:] in ('.mp3','.wav','.mp4')]\n",
    "random.shuffle(media_paths)\n",
    "\n",
    "for media_path in media_paths:\n",
    "    try:\n",
    "        print(media_path)\n",
    "\n",
    "        snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "        classifications = []\n",
    "\n",
    "        for i in range(int(attk.duration(media_path)/resolution_secs)):\n",
    "            try:\n",
    "                snd.subclip(i * resolution_secs , (i * resolution_secs) + resolution_secs).write_audiofile('/tmp/temp_clip.wav')\n",
    "                classifications.append(classify_clip('/tmp/temp_clip.wav'))\n",
    "            except:\n",
    "                classifications.append(0.0)\n",
    "                print(\"Error: \" + str(i))\n",
    "\n",
    "    ## Writing classification output to CSV\n",
    "\n",
    "        classifier_threshold = 0.0      # Classifier values below this threshold will be discarded\n",
    "\n",
    "        csv_path = media_path[:-4]+'_mlpc4096_scaled_labels_'+str(resolution_secs)+'s.csv'\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        with open(csv_path,'w') as fo:\n",
    "            duration = resolution_secs\n",
    "            for value in classifications:\n",
    "                if value >= classifier_threshold:\n",
    "                    start = counter * resolution_secs\n",
    "                    fo.write(str(start) + ',' + str(duration) +','+ str(value) + ',' + speaker_1_label + '\\n')\n",
    "                counter+=1\n",
    "\n",
    "    ## Writing filtered classification output to CSV\n",
    "\n",
    "        classifier_threshold = 0.25      # Classifier values below this threshold will be discarded\n",
    "\n",
    "        csv_path = media_path[:-4]+'_mlpc4096_scaled_labels_filtered_10_frame_window_'+str(resolution_secs)+'s.csv'\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        with open(csv_path,'w') as fo:\n",
    "            duration = resolution_secs\n",
    "            for value in attk.smooth(classifications):\n",
    "                if value >= classifier_threshold:\n",
    "                    start = counter * resolution_secs\n",
    "                    fo.write(str(start) + ',' + str(duration) +','+ str(value) + ',' + speaker_1_label + '\\n')\n",
    "                counter+=1\n",
    "\n",
    "\n",
    "    ## Writing filtered classification output to CSV\n",
    "\n",
    "        classifier_threshold = 0.25      # Classifier values below this threshold will be discarded\n",
    "\n",
    "        csv_path = media_path[:-4]+'_mlpc4096_scaled_labels_filtered_5_frame_window_'+str(resolution_secs)+'s.csv'\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        with open(csv_path,'w') as fo:\n",
    "            duration = resolution_secs\n",
    "            for value in attk.smooth(classifications):\n",
    "                if value >= classifier_threshold:\n",
    "                    start = counter * resolution_secs\n",
    "                    fo.write(str(start) + ',' + str(duration) +','+ str(value) + ',' + speaker_1_label + '\\n')\n",
    "                counter+=1\n",
    "\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Classifying a long audio file\n",
    "\n",
    "resolution_secs = 1.0\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/Obama_test_audio')\n",
    "\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "media_paths = [os.path.abspath(item) for item in os.listdir('./') if item[-4:] in ('.mp3','.wav')]\n",
    "random.shuffle(media_paths)\n",
    "\n",
    "for media_path in media_paths:\n",
    "    try:\n",
    "        print media_path\n",
    "\n",
    "        snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "        classifications = []\n",
    "\n",
    "        for i in range(int(attk.duration(media_path)/resolution_secs)):\n",
    "            try:\n",
    "                snd.subclip(i * resolution_secs , (i * resolution_secs) + resolution_secs).write_audiofile('/tmp/temp_clip.wav')\n",
    "                classifications.append(classify_clip('/tmp/temp_clip.wav'))\n",
    "            except:\n",
    "                classifications.append(0.0)\n",
    "                print(\"Error: \" + str(i))\n",
    "\n",
    "    ## Writing classification output to CSV\n",
    "\n",
    "        classifier_threshold = 0.0      # Classifier values below this threshold will be discarded\n",
    "\n",
    "        os.chdir('/sharedfolder/sida_classifier')\n",
    "\n",
    "        csv_path = media_path[:-4]+'_mlpc4096_scaled_labels_'+str(resolution_secs)+'s.csv'\n",
    "\n",
    "        counter=0\n",
    "\n",
    "        with open(csv_path,'w') as fo:\n",
    "            duration = resolution_secs\n",
    "            for value in classifications:\n",
    "                if value >= classifier_threshold:\n",
    "                    start = counter * resolution_secs\n",
    "                    fo.write(str(start) + ',' + str(duration) +','+ str(value) + ',' + speaker_1_label + '\\n')\n",
    "                counter+=1\n",
    "\n",
    "    ## Writing filtered classification output to CSV\n",
    "\n",
    "        classifier_threshold = 0.40      # Classifier values below this threshold will be discarded\n",
    "\n",
    "        os.chdir('/sharedfolder/sida_classifier')\n",
    "\n",
    "        csv_path = media_path[:-4]+'_mlpc4096_scaled_labels_filtered_10_frame_window'+str(resolution_secs)+'s.csv'\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        with open(csv_path,'w') as fo:\n",
    "            duration = resolution_secs\n",
    "            for value in attk.smooth(classifications):\n",
    "                if value >= classifier_threshold:\n",
    "                    start = counter * resolution_secs\n",
    "                    fo.write(str(start) + ',' + str(duration) +','+ str(value) + ',' + speaker_1_label + '\\n')\n",
    "                counter+=1\n",
    "\n",
    "\n",
    "    ## Writing filtered classification output to CSV\n",
    "\n",
    "        classifier_threshold = 0.40      # Classifier values below this threshold will be discarded\n",
    "\n",
    "        os.chdir('/sharedfolder/sida_classifier')\n",
    "\n",
    "        csv_path = media_path[:-4]+'_mlpc4096_scaled_labels_filtered_5_frame_window'+str(resolution_secs)+'s.csv'\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        with open(csv_path,'w') as fo:\n",
    "            duration = resolution_secs\n",
    "            for value in attk.smooth(classifications):\n",
    "                if value >= classifier_threshold:\n",
    "                    start = counter * resolution_secs\n",
    "                    fo.write(str(start) + ',' + str(duration) +','+ str(value) + ',' + speaker_1_label + '\\n')\n",
    "                counter+=1\n",
    "\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
